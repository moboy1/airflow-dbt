[2023-11-27T17:18:37.688+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: airbyte_example_airflow_dag.airbyte_trigger_sync __airflow_temporary_run_2023-11-27T17:18:36.892811+00:00__ [queued]>
[2023-11-27T17:18:37.694+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: airbyte_example_airflow_dag.airbyte_trigger_sync __airflow_temporary_run_2023-11-27T17:18:36.892811+00:00__ [queued]>
[2023-11-27T17:18:37.694+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2023-11-27T17:18:37.744+0000] {taskinstance.py:1382} INFO - Executing <Task(AirbyteTriggerSyncOperator): airbyte_trigger_sync> on 2023-11-27 17:18:36.892790+00:00
[2023-11-27T17:18:37.753+0000] {standard_task_runner.py:57} INFO - Started process 6238 to run task
[2023-11-27T17:18:37.760+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'airbyte_example_***_dag', 'airbyte_trigger_sync', '__***_temporary_run_2023-11-27T17:18:36.892811+00:00__', '--job-id', '181', '--raw', '--subdir', 'DAGS_FOLDER/example.py', '--cfg-path', '/tmp/tmptwqyvxug']
[2023-11-27T17:18:37.761+0000] {standard_task_runner.py:85} INFO - Job 181: Subtask airbyte_trigger_sync
[2023-11-27T17:18:37.881+0000] {task_command.py:416} INFO - Running <TaskInstance: airbyte_example_airflow_dag.airbyte_trigger_sync __airflow_temporary_run_2023-11-27T17:18:36.892811+00:00__ [running]> on host 471f0a6f2fee
[2023-11-27T17:18:38.147+0000] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='airbyte_example_***_dag' AIRFLOW_CTX_TASK_ID='airbyte_trigger_sync' AIRFLOW_CTX_EXECUTION_DATE='2023-11-27T17:18:36.892790+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='__***_temporary_run_2023-11-27T17:18:36.892811+00:00__'
[2023-11-27T17:18:38.164+0000] {base.py:73} INFO - Using connection ID '***-call-to-airbyte-example' for task execution.
[2023-11-27T17:18:45.687+0000] {airbyte.py:76} INFO - Job 83 was submitted to Airbyte Server
[2023-11-27T17:18:45.734+0000] {taskinstance.py:1937} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "xcom_pkey"
DETAIL:  Key (dag_run_id, task_id, map_index, key)=(44, airbyte_trigger_sync, -1, return_value) already exists.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2479, in xcom_push
    XCom.set(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom.py", line 273, in set
    session.flush()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3589, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "xcom_pkey"
DETAIL:  Key (dag_run_id, task_id, map_index, key)=(44, airbyte_trigger_sync, -1, return_value) already exists.

[SQL: INSERT INTO xcom (dag_run_id, task_id, map_index, key, dag_id, run_id, value, timestamp) VALUES (%(dag_run_id)s, %(task_id)s, %(map_index)s, %(key)s, %(dag_id)s, %(run_id)s, %(value)s, %(timestamp)s)]
[parameters: {'dag_run_id': 44, 'task_id': 'airbyte_trigger_sync', 'map_index': -1, 'key': 'return_value', 'dag_id': 'airbyte_example_airflow_dag', 'run_id': '__airflow_temporary_run_2023-11-27T17:18:36.892811+00:00__', 'value': <psycopg2.extensions.Binary object at 0x773546580810>, 'timestamp': datetime.datetime(2023, 11, 27, 17, 18, 45, 695790, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/gkpj)
[2023-11-27T17:18:45.745+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=airbyte_example_***_dag, task_id=airbyte_trigger_sync, execution_date=20231127T171836, start_date=20231127T171837, end_date=20231127T171845
[2023-11-27T17:18:45.827+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 181 for task airbyte_trigger_sync ((psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "xcom_pkey"
DETAIL:  Key (dag_run_id, task_id, map_index, key)=(44, airbyte_trigger_sync, -1, return_value) already exists.

[SQL: INSERT INTO xcom (dag_run_id, task_id, map_index, key, dag_id, run_id, value, timestamp) VALUES (%(dag_run_id)s, %(task_id)s, %(map_index)s, %(key)s, %(dag_id)s, %(run_id)s, %(value)s, %(timestamp)s)]
[parameters: {'dag_run_id': 44, 'task_id': 'airbyte_trigger_sync', 'map_index': -1, 'key': 'return_value', 'dag_id': 'airbyte_example_airflow_dag', 'run_id': '__airflow_temporary_run_2023-11-27T17:18:36.892811+00:00__', 'value': <psycopg2.extensions.Binary object at 0x773546580810>, 'timestamp': datetime.datetime(2023, 11, 27, 17, 18, 45, 695790, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/gkpj); 6238)
[2023-11-27T17:18:45.845+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2023-11-27T17:18:45.862+0000] {taskinstance.py:2778} INFO - 0 downstream tasks scheduled from follow-on schedule check
